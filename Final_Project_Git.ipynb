{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ac14bWT4cBPt"
   },
   "source": [
    "## Reading Git Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-uwBvdZncBPv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXtuGWpOcBPw"
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUYiuavQcBPx"
   },
   "outputs": [],
   "source": [
    "gcs_folder = 'gs://msca-bdp-data-open/final_project_git'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rchxP_aocBPx"
   },
   "source": [
    "#### Check data size in GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thpK2FYBcBPx",
    "outputId": "45f2e2d6-a7ce-4515-be5d-b77564ae3ac2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total directory size: 1.36 TiB     gs://msca-bdp-data-open/final_project_git\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cmd = 'gsutil du -s -h ' + gcs_folder\n",
    "\n",
    "p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "for line in p.stdout.readlines():\n",
    "    print (f'Total directory size: {line}')\n",
    "\n",
    "retval = p.wait() # Wait for the child process to terminate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXh5D2a3cBPy"
   },
   "source": [
    "### Read Git data from GCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KA3jbNDcBPy"
   },
   "source": [
    "#### Languages\n",
    "Programming languages by repository as reported by GitHub's https://developer.github.com/v3/repos/#list-languages API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZYZzaoGcBPy",
    "outputId": "48d5c469-00a1-4f73-e894-7b3893c37e34"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:=============================>                             (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records read from dataframe *languages*: 3,325,634\n",
      "CPU times: user 4.7 ms, sys: 4.88 ms, total: 9.59 ms\n",
      "Wall time: 9.49 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_languages = spark.read.parquet(os.path.join(gcs_folder, 'languages'))\n",
    "print(f'Records read from dataframe *languages*: {df_languages.count():,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ez3IGGqPcBPz",
    "outputId": "4f9c627e-1877-436a-c26a-34c981cd49d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- repo_name: string (nullable = true)\n",
      " |-- language: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- bytes: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_languages.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBnkYk09cBPz"
   },
   "source": [
    "#### Licenses\n",
    "Open source license SPDX code for each repository as detected by https://developer.github.com/v3/licenses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLpIoHskcBP0",
    "outputId": "5e655851-9823-4ef8-b5fe-a81c9b0072b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records read from dataframe *licenses*: 3,325,634\n",
      "CPU times: user 3.17 ms, sys: 484 µs, total: 3.66 ms\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_licenses = spark.read.parquet(os.path.join(gcs_folder, 'licenses'))\n",
    "print(f'Records read from dataframe *licenses*: {df_licenses.count():,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKOrcInzcBP0",
    "outputId": "a0fece29-8a5a-4e0f-df2c-ba139820070e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- repo_name: string (nullable = true)\n",
      " |-- license: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_licenses.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhbykvVYcBP0"
   },
   "source": [
    "#### Commits\n",
    "Unique Git commits from open source repositories on GitHub, pre-grouped by repositories they appear in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QwYkP0DcBP0",
    "outputId": "6f3219da-8ef7-437d-e877-8f699df5ca59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records read from dataframe *commits*: 265,419,190\n",
      "CPU times: user 61.3 ms, sys: 9.04 ms, total: 70.3 ms\n",
      "Wall time: 23.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_commits = spark.read.parquet(os.path.join(gcs_folder, 'commits'))\n",
    "print(f'Records read from dataframe *commits*: {df_commits.count():,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUpdI2gdcBP1",
    "outputId": "98d812e3-31c5-4464-dc3a-edb927b57db7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- commit: string (nullable = true)\n",
      " |-- tree: string (nullable = true)\n",
      " |-- parent: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- author: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- email: string (nullable = true)\n",
      " |    |-- time_sec: long (nullable = true)\n",
      " |    |-- tz_offset: long (nullable = true)\n",
      " |    |-- date: struct (nullable = true)\n",
      " |    |    |-- seconds: long (nullable = true)\n",
      " |    |    |-- nanos: long (nullable = true)\n",
      " |-- committer: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- email: string (nullable = true)\n",
      " |    |-- time_sec: long (nullable = true)\n",
      " |    |-- tz_offset: long (nullable = true)\n",
      " |    |-- date: struct (nullable = true)\n",
      " |    |    |-- seconds: long (nullable = true)\n",
      " |    |    |-- nanos: long (nullable = true)\n",
      " |-- subject: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- trailer: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- key: string (nullable = true)\n",
      " |    |    |-- value: string (nullable = true)\n",
      " |    |    |-- email: string (nullable = true)\n",
      " |-- difference: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- old_mode: long (nullable = true)\n",
      " |    |    |-- new_mode: long (nullable = true)\n",
      " |    |    |-- old_path: string (nullable = true)\n",
      " |    |    |-- new_path: string (nullable = true)\n",
      " |    |    |-- old_sha1: string (nullable = true)\n",
      " |    |    |-- new_sha1: string (nullable = true)\n",
      " |    |    |-- old_repo: string (nullable = true)\n",
      " |    |    |-- new_repo: string (nullable = true)\n",
      " |-- difference_truncated: boolean (nullable = true)\n",
      " |-- repo_name: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- encoding: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_commits.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRMSb6qxcBP1"
   },
   "source": [
    "#### Contents\n",
    "Unique file contents of text files under 1 MiB on the HEAD branch.  \n",
    "Can be joined to `files` dataset using the id columns to identify the repository and file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ph5tyzbQcBP1",
    "outputId": "414b14f3-3cae-44fb-ce0b-9c88e60622a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records read from dataframe *commits*: 281,191,977\n",
      "CPU times: user 20 ms, sys: 0 ns, total: 20 ms\n",
      "Wall time: 7.21 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_contents = spark.read.parquet(os.path.join(gcs_folder, 'contents'))\n",
    "print(f'Records read from dataframe *commits*: {df_contents.count():,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QjOen14KcBP1",
    "outputId": "f9840313-a26a-476b-eb24-48f8f4ca1e84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- size: long (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- binary: boolean (nullable = true)\n",
      " |-- copies: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_contents.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6FuuqVYcBP2"
   },
   "source": [
    "#### Files\n",
    "File metadata for all files at HEAD.  \n",
    "Join with `contents` dataset on id columns to search text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1GXm762cBP2",
    "outputId": "069ddaed-6e3f-4962-f6f7-01a85bb7c11b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records read from dataframe *files*: 2,309,424,945\n",
      "CPU times: user 8.72 ms, sys: 913 µs, total: 9.64 ms\n",
      "Wall time: 4.62 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_files = spark.read.parquet(os.path.join(gcs_folder, 'files'))\n",
    "print(f'Records read from dataframe *files*: {df_files.count():,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i23WsqJDcBP2",
    "outputId": "a0eb35c7-5430-4245-87ab-05209ea20c22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- repo_name: string (nullable = true)\n",
      " |-- ref: string (nullable = true)\n",
      " |-- path: string (nullable = true)\n",
      " |-- mode: long (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- symlink_target: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_files.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YqXIF6VOcBP2",
    "outputId": "db668107-45f6-473c-db25-f920e141402e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thu, 07 September 2023 13:58:37'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "datetime.datetime.now(pytz.timezone('US/Central')).strftime(\"%a, %d %B %Y %H:%M:%S\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
